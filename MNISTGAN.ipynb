{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90823170",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import ReLU\n",
    "from tensorflow.keras.layers import (Conv2D,LeakyReLU,Dense,Flatten,ZeroPadding2D,\n",
    "                                     Dropout,BatchNormalization,UpSampling2D,\n",
    "                                     GlobalMaxPooling2D,Reshape,Conv2DTranspose)\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import Model, callbacks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83406163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000\n"
     ]
    }
   ],
   "source": [
    "epoch=1000\n",
    "if epoch %500 == 0:\n",
    "    print('Epoch {}'.format(epoch))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "998e78cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('x_train.npy')\n",
    "X_test = np.load('x_test.npy')\n",
    "y_train = np.load('y_train.npy')\n",
    "y_test = np.load('y_test.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7bb6273b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32') /255\n",
    "X_test = X_test /255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49e80c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim= 128\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3ad21118",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-27 15:33:38.428729: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 188160000 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "all_images = np.reshape(X_train,(-1,28,28,1))\n",
    "dataset = tf.data.Dataset.from_tensor_slices(all_images)\n",
    "dataset = dataset.shuffle(buffer_size=1024).batch(batch_size).prefetch(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b107966b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Create_Models():\n",
    "    def __init__(self,latent_dim):\n",
    "        self.latent_dim= latent_dim\n",
    "    \n",
    "    def build_disc(self):\n",
    "        model = Sequential()\n",
    "        model.add(ZeroPadding2D(padding=(1, 1), input_shape=(28, 28,1)))\n",
    "        model.add(Conv2D(32,3))\n",
    "        model.add(ReLU())\n",
    "        model.add(Dropout(0.3))\n",
    "            \n",
    "        model.add(Conv2D(64,3,padding='same'))\n",
    "        model.add(ReLU())\n",
    "        model.add(MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "        \n",
    "        model.add(Conv2D(128,3,strides=1,padding='same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(ReLU())\n",
    "        model.add(Dropout(0.5))\n",
    "        \n",
    "        model.add(Conv2D(256,3,strides=1,padding='same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(ReLU())\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        model.add(Conv2D(128,3,strides=1,padding='same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(ReLU())\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        model.add(Dropout(0.5))\n",
    "        \n",
    "        model.add(Dense(32, activation='relu')) \n",
    "        model.add(Dense(1, activation='sigmoid')) \n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def build_gen(self):\n",
    "        model = Sequential()\n",
    "        \n",
    "        model.add(Dense(7*7*128,input_dim =self.latent_dim))\n",
    "        model.add(ReLU())\n",
    "        model.add(Reshape((7,7,128)))\n",
    "\n",
    "        model.add(Conv2DTranspose(128,4,strides=2,padding='same'))\n",
    "        model.add(ReLU())\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "        \n",
    "        model.add(Conv2DTranspose(64,4,strides=1,padding='same'))\n",
    "        model.add(ReLU())\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "\n",
    "        model.add(Conv2DTranspose(32,4,strides=2,padding='same'))\n",
    "        model.add(ReLU())\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        \n",
    "    \n",
    "        model.add(Conv2D(1,7,padding='same',activation='tanh'))\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8318204b",
   "metadata": {},
   "outputs": [],
   "source": [
    "creat_model = Create_Models(latent_dim)\n",
    "generator= creat_model.build_gen()\n",
    "discriminator= creat_model.build_disc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2f1242a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_25 (Dense)            (None, 6272)              809088    \n",
      "                                                                 \n",
      " re_lu_67 (ReLU)             (None, 6272)              0         \n",
      "                                                                 \n",
      " reshape_6 (Reshape)         (None, 7, 7, 128)         0         \n",
      "                                                                 \n",
      " conv2d_transpose_18 (Conv2D  (None, 14, 14, 128)      262272    \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " re_lu_68 (ReLU)             (None, 14, 14, 128)       0         \n",
      "                                                                 \n",
      " batch_normalization_43 (Bat  (None, 14, 14, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_transpose_19 (Conv2D  (None, 14, 14, 64)       131136    \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " re_lu_69 (ReLU)             (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " batch_normalization_44 (Bat  (None, 14, 14, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_transpose_20 (Conv2D  (None, 28, 28, 32)       32800     \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " re_lu_70 (ReLU)             (None, 28, 28, 32)        0         \n",
      "                                                                 \n",
      " batch_normalization_45 (Bat  (None, 28, 28, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_49 (Conv2D)          (None, 28, 28, 1)         1569      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,237,761\n",
      "Trainable params: 1,237,313\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f8de49c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCGAN(Model):\n",
    "    def __init__(self, discriminator, generator, latent_dim,*args,**kwargs):\n",
    "        super(DCGAN, self).__init__(*args,**kwargs)\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "    def compile(self, d_opt, g_opt,loss_fn,*args,**kwargs):\n",
    "        super(DCGAN, self).compile(*args,**kwargs)\n",
    "        self.d_opt = d_opt\n",
    "        self.g_opt =g_opt\n",
    "        self.loss_fn = loss_fn\n",
    "        \n",
    "    def train_step(self, real_images):\n",
    "        batch_size= tf.shape(real_images)[0]\n",
    "        random_latent_vects = tf.random.normal(shape=(batch_size,self.latent_dim))\n",
    "        gen_images = self.generator(random_latent_vects)\n",
    "        combind_images= tf.concat([gen_images, real_images],axis=0)\n",
    "        \n",
    "        \n",
    "        labels = tf.concat([tf.ones((batch_size,1)), tf.zeros((batch_size,1))],axis=0)\n",
    "        labels += 0.04* tf.random.uniform(tf.shape(labels))\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(combind_images)\n",
    "            d_loss = self.loss_fn(labels, predictions)\n",
    "            \n",
    "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
    "        self.d_opt.apply_gradients(\n",
    "            zip(grads, self.discriminator.trainable_weights)\n",
    "        )\n",
    "        \n",
    "        \n",
    "        random_latent_vects = tf.random.normal(shape=(batch_size,self.latent_dim))\n",
    "        fake_labels = tf.zeros((batch_size, 1))\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(self.generator(random_latent_vects))\n",
    "            g_loss = self.loss_fn(fake_labels,predictions)\n",
    "            \n",
    "\n",
    "        grads = tape.gradient(g_loss,self.generator.trainable_weights)\n",
    "        self.g_opt.apply_gradients(\n",
    "            zip(grads,self.generator.trainable_weights)\n",
    "        )\n",
    "        \n",
    "        \n",
    "        return {\"d_loss\":d_loss,\"g_loss\":g_loss}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7ec0f3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCGAN_Monitor(callbacks.Callback):\n",
    "    def __init__(self,latent_dim):\n",
    "        self.latent_dim = latent_dim\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        random_latent_vects =tf.random.normal(shape=(16, self.latent_dim))\n",
    "        gen_images = self.model.generator(random_latent_vects)\n",
    "        \n",
    "        plt.close('all')\n",
    "        \n",
    "        fix, axs = plt.subplots(4,4, figsize(4,4), sharey= True, sharex=True)\n",
    "        \n",
    "        c=0 \n",
    "        for i in range(4):\n",
    "            for j in range(4):\n",
    "                axs[i,j].imshow(gen_images[c,:,:,0],cmap='gray')\n",
    "                axs[i,j].axis('off')\n",
    "                c+=1\n",
    "                \n",
    "        fig.show()\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b47327",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-27 15:35:03.252615: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 18464768 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "544/938 [================>.............] - ETA: 15:51 - d_loss: 0.6923 - g_loss: 0.7142"
     ]
    }
   ],
   "source": [
    "epochs=1\n",
    "dcgan = DCGAN(discriminator=discriminator,generator=generator,latent_dim=latent_dim)\n",
    "dcgan.compile(\n",
    "    d_opt=tf.keras.optimizers.Adam(learning_rate=0.0002,beta_1=0.5),\n",
    "    g_opt=tf.keras.optimizers.Adam(learning_rate=0.0002,beta_1=0.5),\n",
    "    loss_fn=tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    ")\n",
    "dcgan.fit(dataset,epochs=epochs,callbacks=[DCGAN_Monitor(latent_dim=latent_dim)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
